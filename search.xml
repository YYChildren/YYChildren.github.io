<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ubuntu下安装MooseFS单机版]]></title>
    <url>%2F2018%2F04%2F04%2Fmoosefs-install%2F</url>
    <content type="text"><![CDATA[介绍MooseFS，是千兆级的分布式的文件系统，遵循 POSIX 协议。 资源官方文档https://moosefs.com/ github 地址https://github.com/moosefs/moosefs 安装步骤添加源 Add the key: 1wget -O - https://ppa.moosefs.com/moosefs.key | apt-key add - Add an appropriate repository entry in /etc/apt/sources.list.d/moosefs.list: 1echo &quot;deb http://ppa.moosefs.com/moosefs-3/apt/ubuntu/xenial xenial main&quot; &gt; /etc/apt/sources.list.d/moosefs.list Then run: 1apt update 安装 moosefs-master 安装 1apt install moosefs-master 启动 1mfsmaster start 添加host: /etc/hosts 1192.168.8.30 mfsmaster 安装 moosefs-chunkserver 安装 1apt install moosefs-chunkserver 在/etc/mfs/mfshdd.cfg 添加1个或多个路径，作为分区存储数据，例如 123/data/database/mfs/chunks1/data/database/mfs/chunks2/data/database/mfs/chunks3 建议使用XFS作为底层文件系统 创建目录和授权 123mkdir -p /data/database/mfs/chunks1 /data/database/mfs/chunks2 /data/database/mfs/chunks3chown mfs:mfs /data/database/mfs/chunks1 /data/database/mfs/chunks2 /data/database/mfs/chunks3chmod 770 /data/database/mfs/chunks1 /data/database/mfs/chunks2 /data/database/mfs/chunks3 启动 1mfschunkserver start 客户端：挂载MooseFS 文件系统 安装 1apt install moosefs-client 挂载 12mkdir /data/mfsmount -t moosefs mfsmaster: /data/mfs 可以在/etc/fstab下添加MooseFS 的挂载 1mfsmaster: /data/mfs moosefs defaults,mfsdelayedinit 0 0 现在，可以切换到 /data/mfs 管理你的文件 web 监控（可选） 安装 1apt install moosefs-cgi moosefs-cgiserv moosefs-cli 启动web监控 1mfscgiserv start 在http://mfsmaster:9425 查看moose文件系统情况 moosefs-metalogger（可选，建议） 强烈建议在不是master节点的机器上安装至少一个Metalogger, Metalogger 不断地同步和备份元数据。 安装 1apt install moosefs-metalogger 启动 1mfsmetalogger start]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于erlang动态编译的简单配置方案：econfig]]></title>
    <url>%2F2017%2F11%2F01%2Feconfig%2F</url>
    <content type="text"><![CDATA[前提在使用erlang 编程的时候，经常需要抽离配置文件。 通常配置方式有以下三种: 使用ets存储。 使用erlang 的 application environment，实际上也是使用ets存储的。文档参考 使用动态编译，将配置编译成erlang模块。这样程序可以直接访问代码区，并且无锁，另外由于erlang本身将代码保存两份的热更新机制，在更新配置的时候不会出现短暂读取不到配置的情况。单这种方案有个缺点，在配置过多的情况下，动态编译会比较慢。 使用动态编译构建配置 我根据ejabberd的dynamic_compile.erl 构建了一个简单的基于动态编译的配置方案： econfig 使用例子123456789101112131415161718KVs = [&#123;1,1&#125;, &#123;2,2&#125;, &#123;3,3&#125;],TestCase = [ &#123;test1, KVs&#125;, &#123;test2, fun() -&gt; KVs end&#125;],econfig:reload_config(TestCase),%% or[econfig:reload_config(TestCase) || C &lt;- TestCase],%% 访问单个配置1 = econfig:find(test1, 1),%% 访问不存在的配置undefined = econfig:all(4),%% 访问所有配置（根据key排序）KVs = econfig:all(test1).]]></content>
  </entry>
  <entry>
    <title><![CDATA[impala 解析json]]></title>
    <url>%2F2017%2F10%2F17%2Fparse-json-in-impala%2F</url>
    <content type="text"><![CDATA[前提直接通过hql查询字段为json字符串里的值，比如1获取&apos;&#123;&quot;keyword&quot;:1&#125;&apos; 的keyword值 1 网上相关的文章 相关issue： https://issues.apache.org/jira/browse/IMPALA-376 这篇issue提到impala官方仍然为实现impala的json函数，但是评论中有提到2中方法 直接引用hive的udf 开源的实现： https://github.com/nazgul33/impala-get-json-object-udf 为了简单起见，我直接使用了第一种方案，impala引入HiveUDF的方法参考： https://www.cloudera.com/documentation/enterprise/latest/topics/impala_udf.html#udfs_hive 该函数的使用方法参考：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF 在CDH 集群上的实现12345678sudo -u impala hadoop fs -mkdir -p /user/impala/udfsudo -u impala hadoop fs -put -f /opt/cloudera/parcels/CDH/jars/hive-exec-*.jar /user/impala/udf/hive-exec.jarimpala-shell -q &quot;CREATE DATABASE IF NOT EXISTS udf;USE udf;DROP FUNCTION IF EXISTS udf.get_json_object(string, string);CREATE FUNCTION udf.get_json_object(string, string) returns string location &apos;/user/impala/udf/hive-exec.jar&apos; symbol=&apos;org.apache.hadoop.hive.ql.udf.UDFJson&apos;;&quot; 测试123456Query: select udf.get_json_object(&apos;&#123;&quot;keyword&quot;:1&#125;&apos;, &apos;$.keyword&apos;)+---------------------------------------------------+| udf.get_json_object(&apos;&#123;&quot;keyword&quot;:1&#125;&apos;, &apos;$.keyword&apos;) |+---------------------------------------------------+| 1 |+---------------------------------------------------+]]></content>
  </entry>
  <entry>
    <title><![CDATA[pyspark 报错问题]]></title>
    <url>%2F2017%2F04%2F01%2Fpyspark-error%2F</url>
    <content type="text"><![CDATA[运行代码123# pyspark&gt;&gt;&gt; textFile = sc.textFile(&quot;/tmp/1.sh&quot;)&gt;&gt;&gt; textFile.count() 报错1Python in worker has different version 2.6 than that in driver 2.7, PySpark cannot run with different minor versions 原因 pytspark 启动时使用的是python2.7 内部脚本设置的PYSPARK_PYTHON 是python2.6 解决增加 config/spark-env.sh 配置1PYSPARK_PYTHON=/usr/local/bin/python CDH 解决办法]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hadoop NameNode 无法启动：删除SnapShot所导致]]></title>
    <url>%2F2017%2F02%2F05%2Fnamenode-start-failed-for-snapshot%2F</url>
    <content type="text"><![CDATA[事件回顾2017-02-03 14:14 时看到Hadoop Namenode的swap占用较高，于是尝试重启NameNode以释放Swap。想不到竟然无法启动。 日志如下： 123456789101112131415161718192021222017-02-03 14:15:09,218 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.java.lang.NullPointerException at org.apache.hadoop.hdfs.server.namenode.INodeDirectory.addChild(INodeDirectory.java:531) at org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode$Loader.addToParent(FSImageFormatPBINode.java:252) at org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode$Loader.loadINodeDirectorySection(FSImageFormatPBINode.java:202) at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.loadInternal(FSImageFormatProtobuf.java:261) at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.load(FSImageFormatProtobuf.java:180) at org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat.java:226) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:929) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:913) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:732) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:668) at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:281) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1061) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:765) at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:604) at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:663) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:830) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:814) at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1507) at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1575)2017-02-03 14:15:09,238 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1 Hadoop 版本信息我们当时使用的Hadoop版本为CDH5.4.9 问题发现 Google之，得到Apache 官方有提到该Bug 地址：https://issues.apache.org/jira/browse/HDFS-9406 另外CDH官方有提到解决该问题的版本 地址：https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_rn_fixed_in_54.html#fixed_issues_5410 问题解释 当删除一个包含INode的最新记录的快照时，fsimage有可能崩溃，因为更早快照的diff的create-list 和 父亲INodeDirectory的child list没有清理。 When deleting a snapshot that contains the last record of a given INode, the fsimage may become corrupt because the create list of the snapshot diff in the previous snapshot and the child list of the parent INodeDirectory are not cleaned. 解决过程 尝试以 2017-02-03 12 时的 fsimage 恢复，发现问题依旧。 升级CDH 版本到5.4.11，发现问题依旧 继续升级版本到5.7.5，发现问题依旧 查看修复版本的关键文件 INodeDirectory.java、FSImageFormatPBINode.java、FSImageFormatProtobuf.java（位于hadoop-common项目），发现并没有对空指针异常做处理的代码。 查看patch，实际上也只是让删除快照变得正常，但是对已经出问题的fsimage没有做好兼容。 针对CDH5.7.5-release，尝试修改代码，在Namenode启动时忽略Null 的INode，主要改动如下 编译替换后发现了新的异常： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051522017-02-04 15:41:08,581 ERROR org.apache.hadoop.hdfs.server.namenode.FSImage: Failed to load image from FSImageFile(file=/data/dfs/nn/current/fsimage_0000000005899107393, cpktTxId=0000000005899107393)java.io.IOException: Cannot find an INode associated with the INode FlumeData.1482923297645 in created list while loading FSImage. at org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotFSImageFormat.loadCreated(SnapshotFSImageFormat.java:158) at org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot$Loader.loadCreatedList(FSImageFormatPBSnapshot.java:244) at org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot$Loader.loadDirectoryDiffList(FSImageFormatPBSnapshot.java:338) at org.apache.hadoop.hdfs.server.namenode.snapshot.FSImageFormatPBSnapshot$Loader.loadSnapshotDiffSection(FSImageFormatPBSnapshot.java:189) at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.loadInternal(FSImageFormatProtobuf.java:271) at org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf$Loader.load(FSImageFormatProtobuf.java:181) at org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat.java:226) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:948) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:932) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:751) at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:682) at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:291) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1096) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:778) at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:609) at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:670) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:838) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:817) at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1537) at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1605)2017-02-04 15:41:08,657 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimagejava.io.IOException: Failed to load FSImage file, see error(s) above for more info. at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:697) at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:291) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1096) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:778) at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:609) at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:670) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:838) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:817) at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1537) at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1605)2017-02-04 15:41:08,660 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:500702017-02-04 15:41:08,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...2017-02-04 15:41:08,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.2017-02-04 15:41:08,761 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.2017-02-04 15:41:08,762 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.java.io.IOException: Failed to load FSImage file, see error(s) above for more info. at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:697) at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:291) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1096) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:778) at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:609) at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:670) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:838) at org.apache.hadoop.hdfs.server.namenode.NameNode.&lt;init&gt;(NameNode.java:817) at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1537) at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1605)2017-02-04 15:41:08,764 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 12017-02-04 15:41:08,765 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 根据提示，继续修改代码 重新编译修改后的代码，采用的Java版本为http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.7.5/RPMS/x86_64/oracle-j2sdk1.7-1.7.0+update67-1.x86_64.rpm，编译前需要安装protobuf-2.5.0和protobuf-compile-2.5.0，编译指令为 1mvn package -Pdist -DskipTests -Dtar 替换集群NameNode和SecondaryNamenode 下的 /opt/cloudera/parcels/CDH/jars/hadoop-hdfs-2.6.0-cdh5.7.5.jar 为上面编译后的 hadoop-common-cdh5.7.5-release/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-2.6.0-cdh5.7.5.jar 启动NameNode 成功修复总结 目前暂时通过忽略空节点的方式来绕过fsimage的问题，但是由于对hadoop了解还不够深入，不确定会不会引入新的问题，建议最好启动后备份数据，然后重整集群再恢复。 备份一定要做好，开源的方案有可能存在bug，导致各种问题。要做到无法何种故障，都有恢复的手段。 最后重点感谢公司强大的大佬和强大运维支持。]]></content>
  </entry>
  <entry>
    <title><![CDATA[单节点 zookeeper 安装]]></title>
    <url>%2F2016%2F08%2F31%2Finstall-single-node-zookeeper%2F</url>
    <content type="text"><![CDATA[安装过程12345678910111213141516# 下载cd /optwget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.8/zookeeper-3.4.8.tar.gztar -axvf zookeeper-3.4.8.tar.gzcd zookeeper-3.4.8# 环境变量cat &gt;&gt; ~/.bashrc &lt;&lt;EOF########## ZOOKEEPER ####################export ZOOKEEPER_HOME=/opt/zookeeper-3.4.8export PATH=\$PATH:\$ZOOKEEPER_HOME/binexport CLASSPATH=\$CLASSPATH:\$ZOOKEEPER_HOME/lib/*EOF# 使环境变量生效source ~/.bashrc 1234# 配置cp $ZOOKEEPER_HOME/conf/zoo_sample.cfg $ZOOKEEPER_HOME/conf/zoo.cfg# 修改zoo.cfg的datadir配置为dataDir=/data/var/lib/zookeeper 启动1234# 启动$ZOOKEEPER_HOME/bin/zkServer.sh start# 关闭$ZOOKEEPER_HOME/bin/zkServer.sh stop 参考文档 https://zookeeper.apache.org/doc/r3.4.8/ https://zookeeper.apache.org/doc/r3.4.8/zookeeperStarted.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[CentOS6 下安装openresty]]></title>
    <url>%2F2016%2F08%2F11%2Finstall-openresty-on-centos6%2F</url>
    <content type="text"><![CDATA[安装过程 安装依赖库 1yum install -y readline-devel pcre-devel openssl-devel gcc postgresql-devel 下载从https://openresty.org/cn/download.html下载一个发行版 解压安装到/opt/openresty下 123456789tar xzvf ngx_openresty-VERSION.tar.gzcd ngx_openresty-VERSION/./configure --prefix=/opt/openresty \ --with-luajit \ --without-http_redis2_module \ --with-http_iconv_module \ --with-http_postgres_modulemake -j8make install 添加环境变量 123456789cat &gt;&gt; ~/.bashrc &lt;&lt;EOF######## openresty #########export OPENRESTY_HOME=/opt/openrestyexport PATH=\$PATH:\$OPENRESTY_HOME/binexport NGINX_HOME=\$OPENRESTY_HOME/nginxexport PATH=\$PATH:\$NGINX_HOME/sbinexport LUAJIT_HOME=\$OPENRESTY_HOME/luajitexport PATH=\$LUAJIT_HOME/bin:\$PATHEOF 参考 openresty: https://openresty.org/cn/ openresty安装：https://openresty.org/cn/installation.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[apache 的HTTPS设置]]></title>
    <url>%2F2016%2F05%2F05%2Fapache-https-setting%2F</url>
    <content type="text"><![CDATA[配置Apache的HTTP支持 创建并切换到ssl目录 123mkdir -p /etc/httpd/sslchmod 600 /etc/httpd/sslcd /etc/httpd/ssl 生成证书和密钥 123456# 建立服务器密钥openssl genrsa -out server.key 1024# 建立服务器公钥 openssl req -new -key server.key -out server.csr# 建立服务器证书 openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 修改/etc/httpd/conf.d/ssl.conf 123456Listen Server_FQDN:443SSLEngine onSSLCertificateKeyFile /etc/httpd/ssl/server.keySSLCertificateFile /etc/httpd/ssl/server.crtSSLCACertificateFile /etc/pki/tls/certs/ca-bundle.crtSSLCipherSuite ALL:-ADH:+HIGH:+MEDIUM:-LOW:-SSLv2:-EXP 参考： http://httpd.apache.org/docs/2.2/ http://security-24-7.com/how-to-implement-ssl-on-apache-2-2-15/ http://www.thinksaas.cn/topics/0/280/280017.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[安装Cloudera 5.7.0镜像]]></title>
    <url>%2F2016%2F05%2F04%2Finstall-cloudera-5.7.0-mirror%2F</url>
    <content type="text"><![CDATA[镜像包含 CM5 CDH5 安装Apache HTTP server12345yum install httpd# 查看版本httpd -v# Server version: Apache/2.2.15 (Unix)# Server built: Mar 22 2016 19:03:53 ssl相关模块1yum install -y openssl mod_ssl 启动http服务器注意：这里暂时忽略证书1service httpd start CM与CDHCM 地址 cm5 5.7.0 CDH 地址CDH5 rpm形式 5.7.0CDH5 parcel 下载12345wget http://archive.cloudera.com/cm5/repo-as-tarball/5.7.0/cm5.7.0-centos6.tar.gzwget http://archive.cloudera.com/cdh5/repo-as-tarball/5.7.0/cdh5.7.0-centos6.tar.gzwget http://archive.cloudera.com/cdh5/parcels/5.7.0/CDH-5.7.0-1.cdh5.7.0.p0.45-el6.parcelwget http://archive.cloudera.com/cdh5/parcels/5.7.0/CDH-5.7.0-1.cdh5.7.0.p0.45-el5.parcel.sha1wget http://archive.cloudera.com/cdh5/parcels/5.7.0/manifest.json 解压123456789101112# CMmkdir -p /var/www/html/cm5/redhat/6/x86_64tar xvfz cm5.7.0-centos6.tar.gz -C /var/www/html/cm5/redhat/6/x86_64# CDHmkdir -p /var/www/html/cdh5tar xvfz cdh5.7.0-centos6.tar.gz -C /var/www/html/cdh5mkdir -p /var/www/html/cdh5/parcels/5.7.0/cp CDH-5.7.0-1.cdh5.7.0.p0.45-el6.parcel CDH-5.7.0-1.cdh5.7.0.p0.45-el6.parcel.sha1 manifest.json /var/www/html/cdh5/parcels/5.7.0/cd /var/www/html/cdh5/parcels/ln -s 5.7.0 5.7ln -s 5.7.0 5ln -s 5.7.0 latest 其他文件12345678910111213141516# CM5CM5_DIR=/var/www/html/cm5# CM5 installercd $CM5_DIRwget http://archive.cloudera.com/cm5/installer/5.7.0/cloudera-manager-installer.bin -P installer/5.7.0cd $CM5_DIR/installerln -s 5.7.0 latest# redhatREDHAT_DIR=/var/www/html/redhatmkdir $REDHAT_DIRcd $REDHAT_DIRwget http://archive.cloudera.com/redhat/cdh/RPM-GPG-KEY-cloudera -P cdh/## 或者ln -s $PWD/../cdh5/redhat/6/x86_64/cdh . 权限1chmod -R ugo+rX /var/www/html/cdh 其他机器访问在其他机器添加yum 仓库123456# cat /etc/yum.repos.d/cloudera.repo[cloudera]name=clouderabaseurl=http://hostname/cm5/redhat/6/x86_64/cm/5enabled=1gpgcheck=0 参考 http://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_create_local_package_repo.html#cmig_topic_21_3]]></content>
  </entry>
  <entry>
    <title><![CDATA[CDH 5.7 安装]]></title>
    <url>%2F2016%2F05%2F04%2Finstall-cdh-5.7%2F</url>
    <content type="text"><![CDATA[搭建镜像安装位置：192.168.8.209参考:http://yychildren.leanote.com/post/安装Cloudera-5.7.0镜像/ 准备三台机器123ycj1.mingchao.comycj2.mingchao.comycj3.mingchao.com 安装基本软件安装yum库1yum install -y wget 163的yum库 1wget http://mirrors.163.com/.help/CentOS6-Base-163.repo -P /etc/yum.repos.d epel库 1rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 基本软件123456yum install -y vim lrzsz python openssh openssh-clients# vim# lrzsz# python 2.6/2.7# openssh# openssh-clients host 设置123456# 你的镜像服务器，参考&quot;安装Cloudera 5.7.0镜像&quot;192.168.8.209 archive.cloudera.com192.168.116.21 ycj1.mingchao.com192.168.116.22 ycj2.mingchao.com192.168.116.23 ycj3.mingchao.com 生成ssh密钥对1ssh-keygen 添加公钥ycj1.mingchao.com上做123ssh-copy-id ycj1.mingchao.comssh-copy-id ycj2.mingchao.comssh-copy-id ycj3.mingchao.com 禁用selinux参考：http://www.thegeekstuff.com/2009/06/how-to-disable-selinux-redhat-fedora-debian-unix/永久12cat /etc/selinux/config## 之后重启电脑 12345678910# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of these two values:# targeted - Targeted processes are protected,# mls - Multi Level Security protection.SELINUXTYPE=targeted 临时（没成功）123echo 0 &gt; /selinux/enforce## orsetenforce 0 查看selinux状态12getenforce# Disabled 关闭防火墙永久（需重启）1chkconfig iptables off 临时1service iptables stop yum 不检验ssl原因是5.7.0的访问以https的形式12# 在/etc/yum.conf 下添加sslverify=false 安装Cloudera managerycj1.mingchao.com上做123456wget http://archive.cloudera.com/cm5/installer/5.7.0/cloudera-manager-installer.binchmod u+x cloudera-manager-installer.bin# 从Internet安装sudo ./cloudera-manager-installer.bin# 从本地库安装 （这里不采用）sudo ./cloudera-manager-installer.bin --skip_repo_package=1 安装完后等待，直到123netstat -anp | grep 7180# tcp 0 0 0.0.0.0:7180# 0.0.0.0:* LISTEN 1676/java cloudera-manager登录链接：http://192.168.116.21:7180/账号：admin密码：admin 下一步到 可以选择使用数据包或者使用Parcel 使用以下搜索主机：1ycj[1-3].mingchao.com 继续–安装JDK 选定： 继续–SSH登录凭据 选择： 继续–等待安装 权限问题解决1234sudo -u hdfs hadoop fs -chmod 777 /sudo -u hdfs hadoop fs -mkdir -p /user/spark/applicationHistorysudo -u hdfs hadoop fs -chown -R spark /user/sparksudo -u hdfs hadoop fs -chmod 1777 /user/spark/applicationHistory 安装完成证书问题 报错： 原因没有cloudera的证书 解决 中止安装 yum 不验证ssl123&gt;# 在/etc/yum.conf 下添加&gt;sslverify=false&gt; 卸载失败的主机 重试失败的主机添加证书但在CentOS 6下无效的方法，已经被确定为CentOS的bug：https://www.centos.org/forums/viewtopic.php?t=1073更新ca-certificates12&gt;yum --disablerepo=cloudera-manager -y update ca-certificates&gt; 导出cloudera的证书为cloudera.cer导入证书12345转换格式 .cer 到 .pemopenssl x509 -inform der -in cloudera.cer -out cloudera.pem追加到信任列表cat cloudera.pem &gt;&gt; /etc/pki/tls/certs/ca-bundle.crt&gt; 参考 http://www.cloudera.com/documentation/enterprise/latest/topics/cm_ig_install_path_a.html#cmig_topic_6_5]]></content>
  </entry>
  <entry>
    <title><![CDATA[我眼中的程序]]></title>
    <url>%2F2016%2F04%2F24%2Fprogram-in-my-eyes%2F</url>
    <content type="text"><![CDATA[背景随着程序越写越多，接触的语言逐渐广泛，开始思考程序到底是什么，怎样编写程序。以下是个人的一些理解，并非权威定义，欢迎探讨与批判。 通常介绍尼古拉斯·沃斯 ：算法+数据结构=程序 我的理解算法：对于0个或多个输入数据进行一系列有限步骤之后得出1个或以上的输出结果。本质上是一个行为说明书。数据结构：对数据以及数据之间的关联关系的描述。本质上就是数据。程序：通过上面的理解，可以认为程序=数据+行为 这样说或许比较抽象，可以参考一个例子： 我从商场买了回来一个吊扇，现在我要把她装到我的床上： 那么： 数据：里面的螺丝、扇翼等基本配件可以认为是数据。 行为：介绍如可安装电风扇的说明说就是行为。 程序在编程语言上的体现编程语言大致可以分为三种： 面向过程： 对于一个问题，详细描述解决问题的过程。 典型代表，C语言 面向对象： 重在数据，通过封装将数据抽象化，将方法应用于特定抽象化数据。 工业界主流，C++、Java、Python等 函数式编程： 重在行为，将行为定义成函数，函数可作为参数传递以及作为返回值返回。 schema、erlang、scala等。 可以看到实际上面向对象实际上将重点放在数据的组织上，让程序看起来就像是现实世界上不同个体与整体的映射。而函数式编程这是重在行为，意看起来是将现实中的种种方法步骤以函数作为载体映射到程序里。至于面向过程，我使用较少，不做评论。 那么有没有数据和行为都重点关注的语言呢？有的，如 python：面向对象语言，把一切看做对象，函数也是对象。 scala：函数式编程语言，运行于Java虚拟机。虽然推崇函数式编程，但也提供了对象的封装。 编程语言的两个极端 Lisp：计算的需求，也就是行为的体现。 C：抽象的需求，也就是数据的体现。]]></content>
  </entry>
</search>
